{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About iPython Notebooks ##\n",
    "\n",
    "iPython Notebooks are interactive coding environments embedded in a webpage. You will be using iPython notebooks in this class. Make sure you fill in any place that says `# BEGIN CODE HERE #END CODE HERE`. After writing your code, you can run the cell by either pressing \"SHIFT\"+\"ENTER\" or by clicking on \"Run\" (denoted by a play symbol). Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All). \n",
    "\n",
    " **What you need to remember:**\n",
    "\n",
    "- Run your cells using SHIFT+ENTER (or \"Run cell\")\n",
    "- Write code in the designated areas using Python 3 only\n",
    "- Do not modify the code outside of the designated areas\n",
    "- In some cases you will also need to explain the results. There will also be designated areas for that. \n",
    "\n",
    "Fill in your **NAME** and **AEM** below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"Sotiris Ftiakas\"\n",
    "AEM = \"3076\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ce63642cafb413e7903d83d2f2cd3637",
     "grade": false,
     "grade_id": "cell-f62db6dce1ed3f2e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Assignment 2 - Decision Trees #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "29d61ce286fdb8fd61c7f8e89a9e1339",
     "grade": false,
     "grade_id": "cell-dce2e73cee9a5017",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Welcome to your second assignment. This exercise gives you an introduction to [scikit-learn](https://scikit-learn.org/stable/). A simple but efficient machine learning library in Python. It also gives you a wide understanding on how decision trees work. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "50a108d2f1e1a1ee2fde80743c0543fe",
     "grade": false,
     "grade_id": "cell-83ca2b0456fb85db",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "After this assignment you will:\n",
    "- Be able to use the scikit-learn library and train your own model from scratch.\n",
    "- Be able to train and understand decision trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "396c39a0797964c378ebb90cf18a29de",
     "grade": false,
     "grade_id": "cell-2cef6d48eea484d8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Always run this cell\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "import unittest\n",
    "\n",
    "# USE THIS RANDOM VARIABLE TO PRODUCE THE SAME RESULTS\n",
    "RANDOM_VARIABLE = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Scikit-Learn and Decision Trees ##\n",
    "\n",
    "You are going to use the scikit-learn library to train a model for detecting breast cancer using the [Breast cancer wisconsin (diagnostic) dataset](https://scikit-learn.org/stable/datasets/index.html#breast-cancer-wisconsin-diagnostic-dataset) by training a model using [decision trees](https://scikit-learn.org/stable/modules/tree.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.1** Load the breast cancer dataset using the scikit learn library and split the dataset into train and test set using the appropriate function. Use 30% of the dataset as the test set. Define as X the attributes and as y the target values. Do not forget to set the random_state parameter as the *RANDOM_VARIABLE* defined above. Use this variable for all the random_state parameters in this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4b873328ea05f6ef9c08827168c7b835",
     "grade": false,
     "grade_id": "cell-1f0c2f3918333cf6",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# BEGIN CODE HERE\n",
    "\n",
    "X,y = load_breast_cancer(return_X_y = True)\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=RANDOM_VARIABLE)\n",
    "\n",
    "#END CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3603b2ba8916ffdad9e9c53f31546b4c",
     "grade": true,
     "grade_id": "cell-3f43c895ceaf57a9",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train set:398\n",
      "Size of test set:171\n",
      "Unique classes:2\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of train set:{}\".format(len(y_train)))\n",
    "print(\"Size of test set:{}\".format(len(y_test)))\n",
    "print(\"Unique classes:{}\".format(len(set(y_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "62285a7bd3ab59718b89f7e09de0fea4",
     "grade": false,
     "grade_id": "cell-1ce621a108e76a15",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Expected output**:  \n",
    "Size of train set:398  \n",
    "Size of test set:171  \n",
    "Unique classes:2  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.2** Train two DecisionTree classifiers and report the F1 score. Use the information gain for the one classifier and the Gini impurity for the other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "17197b62614427a979fcbab7ed2734dd",
     "grade": false,
     "grade_id": "cell-a7fa1d29509eb2a1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# BEGIN CODE HERE\n",
    "classifier_gini = DecisionTreeClassifier(criterion=\"gini\",random_state=RANDOM_VARIABLE).fit(X_train,y_train)\n",
    "classifier_igain = DecisionTreeClassifier(criterion=\"entropy\",random_state=RANDOM_VARIABLE).fit(X_train,y_train)\n",
    "\n",
    "prediction_gini = classifier_gini.predict(X_test)\n",
    "prediction_igain = classifier_igain.predict(X_test)\n",
    "\n",
    "f_measure_gini = f1_score(y_test,prediction_gini)\n",
    "f_measure_igain = f1_score(y_test,prediction_igain)\n",
    "\n",
    "#END CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6d9aab4355c27c346f7e6548f233e758",
     "grade": true,
     "grade_id": "cell-09657a82bf4028c4",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-Measure Gini:0.9528301886792453\n",
      "F-Measure Information Gain:0.9724770642201834\n"
     ]
    }
   ],
   "source": [
    "print(\"F-Measure Gini:{}\".format(f_measure_gini))\n",
    "print(\"F-Measure Information Gain:{}\".format(f_measure_igain))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f3facbbef0dd8f25ad12bfec7c174818",
     "grade": false,
     "grade_id": "cell-b0d8630f3b764cf3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Expected output**:  \n",
    "F-Measure Gini:0.9528301886792453  \n",
    "F-Measure Information Gain:0.9724770642201834  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f2532168d16e8c9bffba3d7d8e1efce7",
     "grade": false,
     "grade_id": "cell-591ba122016b6db5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**1.3** Find the maximum depth reached by the tree that used the Gini impurity. Train multiple classifier by modifying the max_depth within the range from 1 to maximum depth and save the f1 scores to lists.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "54cf257e90a3cb5877db81297bedd45c",
     "grade": false,
     "grade_id": "cell-31c58b6161a3907d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# BEGIN CODE HERE\n",
    "depth = classifier_gini.tree_.max_depth\n",
    "fscores_train = []\n",
    "fscores_test = []\n",
    "\n",
    "for i in range (1,depth+1):\n",
    "    gini = DecisionTreeClassifier(criterion=\"gini\",random_state=RANDOM_VARIABLE,max_depth=i).fit(X_train,y_train)\n",
    "    pred_gini = gini.predict(X_train)\n",
    "    f_gini = f1_score(y_train,pred_gini)\n",
    "    \n",
    "    fscores_train.append(f_gini)\n",
    "    \n",
    "    gini = DecisionTreeClassifier(criterion=\"gini\",random_state=RANDOM_VARIABLE,max_depth=i).fit(X_train,y_train)\n",
    "    pred_gini = gini.predict(X_test)\n",
    "    f_gini = f1_score(y_test,pred_gini)\n",
    "    \n",
    "    fscores_test.append(f_gini)\n",
    "    \n",
    "\n",
    "\n",
    "#END CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "70a249937f2f690c6ce855debaed204c",
     "grade": true,
     "grade_id": "cell-0c300109423f53b9",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fscores Train:[0.9392712550607287, 0.9533468559837729, 0.9761904761904762, 0.996, 0.996, 0.9979959919839679, 1.0]\n",
      "Fscores Test:[0.9150943396226415, 0.9444444444444444, 0.9724770642201834, 0.9629629629629629, 0.9629629629629629, 0.9674418604651163, 0.9528301886792453]\n"
     ]
    }
   ],
   "source": [
    "print(\"Fscores Train:{}\".format(fscores_train))\n",
    "print(\"Fscores Test:{}\".format(fscores_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3db472d2b9db7a42cc012cd96fdeb499",
     "grade": false,
     "grade_id": "cell-75789627f20d2c94",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Expected output**:  \n",
    "Fscores Train:[0.9392712550607287, 0.9533468559837729, 0.9761904761904762, 0.996, 0.996, 0.9979959919839679, 1.0]  \n",
    "Fscores Test:[0.9150943396226415, 0.9444444444444444, 0.9724770642201834, 0.9629629629629629, 0.9629629629629629, 0.9674418604651163, 0.9528301886792453]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bca7d4c160c767d27a09b4620d27d56e",
     "grade": false,
     "grade_id": "cell-5906e6d5efa70282",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**1.4** Compare the results from the train set with the results from the test set. What do you notice? Explain your findings. How are you going to choose the max_depth of your model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "424ac10e4e22ca9e32207deee3bf0f57",
     "grade": true,
     "grade_id": "cell-c9c6ea0e40d98b83",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "There are **two(2)** things we can notice on the results.\n",
    "\n",
    "**1)** On the **train-f1_scores** list, as we keep on incrementing the max allowed tree depth, at one point we can see that the f1_score is approaching and finally achieving 100% accuracy, meaning that we have completely overfitted our model to the training dataset.\n",
    "\n",
    "**2)** On the **test-f1_scores** list, as we keep on incrementing the max allowed tree depth, at one point we can see that the f1_score starts to fall, meaning that our model is losing accuracy. This means as well, that we have an overfitting problem after a specific tree depth.\n",
    "\n",
    "To choose the max_depth of a model, a good pre-prunning technique is to **use a condition** which will require a node to have a **minimum amount of points before splitting.** \n",
    "Other than that, there is always the option of **trial and error**, where we can try different depths for our model and see which one gives us the best possible accuracy, while avoiding overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #THATS A TESTING CELL\n",
    "\n",
    "# # BEGIN CODE HERE\n",
    "# income = pd.read_csv(\"income.csv\")\n",
    "# income_test = pd.read_csv(\"income_test.csv\")\n",
    "\n",
    "# #print(\"Keys of income_dataset: \\n\\n{}\\n\\n\".format(income.keys()))\n",
    "\n",
    "# cleandata=income.copy()\n",
    "# cleandata_test=income_test.copy()\n",
    "\n",
    "# #The reason I merge the two datasets is because later, due to one hot encoding, the two datasets have different amount\n",
    "# #of columns\n",
    "\n",
    "# cleandata['train']=1\n",
    "# cleandata_test['train']=0\n",
    "# combined=pd.concat([cleandata,cleandata_test])\n",
    "\n",
    "# #Fill missing values, replacing them with each columns' most frequent value.\n",
    "# combined = combined.apply(lambda x:x.fillna(x.value_counts().index[0])) \n",
    "\n",
    "# #Replacing categorical values with One Hot Encoding method (AKA the dummy method).\n",
    "# combined_encoded = pd.get_dummies(combined, columns=['workclass','education','marital-status','occupation','relationship','race','sex','income'])\n",
    "# combined=pd.concat([combined,combined_encoded],axis=1)\n",
    "\n",
    "# #Split the two datasets now\n",
    "\n",
    "# cleandata = combined[combined['train'] == 1]\n",
    "# cleandata_test = combined[combined['train'] == 0]\n",
    "# cleandata.drop(['train'], axis=1, inplace=True)\n",
    "# cleandata_test.drop(['train'], axis=1, inplace=True)\n",
    "\n",
    "# #print(cleandata.describe(include='all'))\n",
    "# print(\"Keys of income_dataset: \\n\\n{}\\n\\n\".format(cleandata.keys()))\n",
    "# print(\"Keys of income_dataset: \\n\\n{}\\n\\n\".format(cleandata_test.keys()))\n",
    "\n",
    "# X_train = cleandata.iloc[:, :-2].values\n",
    "# y_train = cleandata.iloc[:, -2:].values\n",
    "# X_test = cleandata_test.iloc[:, :-2].values\n",
    "# y_test = cleandata_test.iloc[:, -2:].values\n",
    "\n",
    "# classifier = DecisionTreeClassifier(random_state=RANDOM_VARIABLE).fit(X_train,y_train)\n",
    "\n",
    "# #y_pred=classifier.predict(X_test)\n",
    "\n",
    "# #fScore = f1_score(y_test,y_pred)\n",
    "# accScore = \"\"\n",
    "\n",
    "# #END CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "217666fcc2e383d6f2c1904c9d6a71be",
     "grade": false,
     "grade_id": "cell-9ef42e6c90ea2ffe",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 2.0 Pipelines ##\n",
    "\n",
    "**2.1** In this part of the exercise you are going to build a pipeline from scratch for a classification problem. Load the **income.csv** file and train a DecisionTree model that will predict the *income* variable. This dataset is a modification of the original Adult Income dataset found [here](http://archive.ics.uci.edu/ml/datasets/Adult). Report the f1-score and accuracy score of the test set found in **income_test.csv**. Your pipeline should be able to handle missing values and categorical features (scikit-learn's decision trees do not handle categorical values). You can preprocess the dataset as you like in order to achieve higher scores.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "152ab2dd6861b198b879a78ebadc4ee4",
     "grade": true,
     "grade_id": "cell-dd950ab2eb40d8a4",
     "locked": false,
     "points": 45,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score on test set: 0.67\n",
      "Accuracy on test set: 0.86\n"
     ]
    }
   ],
   "source": [
    "# BEGIN CODE HERE\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "income = pd.read_csv(\"income.csv\")\n",
    "income_test = pd.read_csv(\"income_test.csv\")\n",
    "\n",
    "#print(\"Keys of income_dataset: \\n\\n{}\\n\\n\".format(income.keys()))\n",
    "\n",
    "cleandata=income.copy()\n",
    "cleandata_test=income_test.copy()\n",
    "\n",
    "#Fill missing values, replacing them with each columns' most frequent value.\n",
    "cleandata = cleandata.apply(lambda x:x.fillna(x.value_counts().index[0])) \n",
    "\n",
    "#Replacing categorical values with One Hot Encoding method (AKA the dummy method).\n",
    "cleandata = pd.get_dummies(cleandata, columns=['workclass','education','marital-status','occupation','relationship','race','sex'])\n",
    "cleandata['income'] = LabelEncoder().fit_transform(cleandata.income.values)\n",
    "\n",
    "cleandata_test = pd.get_dummies(cleandata_test, columns=['workclass','education','marital-status','occupation','relationship','race','sex'])\n",
    "cleandata_test['income'] = LabelEncoder().fit_transform(cleandata_test.income.values)\n",
    "\n",
    "cleandata, cleandata_test = cleandata.align(cleandata_test, join='inner', axis=1)  #Inner join to prevent uneven number of columns\n",
    "\n",
    "#print(cleandata.describe(include='all'))\n",
    "#print(\"Keys of income_dataset: \\n\\n{}\\n\\n\".format(cleandata.keys()))\n",
    "#print(\"Keys of income_dataset: \\n\\n{}\\n\\n\".format(cleandata_test.keys()))\n",
    "\n",
    "X_train = cleandata.drop(['income'],axis=1)\n",
    "y_train = cleandata['income'].values\n",
    "X_test = cleandata_test.drop(['income'],axis=1)\n",
    "y_test = cleandata_test['income'].values\n",
    "\n",
    "# print(X_train)\n",
    "# print(y_train)\n",
    "# print(X_test)\n",
    "# print(y_test)\n",
    "\n",
    "classifier = DecisionTreeClassifier(max_depth=10, random_state=RANDOM_VARIABLE).fit(X_train,y_train)\n",
    "\n",
    "y_pred=classifier.predict(X_test)\n",
    "\n",
    "fScore = f1_score(y_test,y_pred)\n",
    "print(\"F1-score on test set: {:.2f}\".format(fScore))\n",
    "accScore = classifier.score(X_test, y_test)\n",
    "print(\"Accuracy on test set: {:.2f}\".format(accScore))\n",
    "\n",
    "\n",
    "#END CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ee9d4c2635307395bdef2efb941106ae",
     "grade": false,
     "grade_id": "cell-2c3327274958bbad",
     "locked": true,
     "points": 20,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "**2.2** Describe the process you followed to achieve the results above. Your description should include, but is not limited to the following \n",
    "- How do you handle missing values and why\n",
    "- How do you handle categorical variables and why\n",
    "- Any further preprocessing steps\n",
    "- How do you evaluate your model and how did you choose its parameters \n",
    "- Report any additional results and comments on your approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8cef3f333ab449ed91b81ea96695e712",
     "grade": false,
     "grade_id": "cell-555d20216f9bbec2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 3.0 Common Issues ## "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.0** Run the following code to define a DecisionTreeModel and load the **income** dataset only with the numerical variables. Then, answer the following questions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ae0f57b86252cc38b02cac3d05e08bbf",
     "grade": false,
     "grade_id": "cell-d7f58621bad12aad",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Load Data\n",
    "columns = ['age','fnlwgt','education_num','hours-per-week',\"capital-loss\",\"capital-gain\",\"income\"]\n",
    "data = pd.read_csv('income.csv',usecols=columns)\n",
    "data_test = pd.read_csv('income_test.csv',usecols=columns)\n",
    "# Convert target variable to 0 and 1\n",
    "data[\"income\"] = data[\"income\"].map({ \"<=50K\": 0, \">50K\": 1 })\n",
    "data_test[\"income\"] = data_test[\"income\"].map({ \"<=50K\": 0, \">50K\": 1 })\n",
    "# Create X and y\n",
    "X_train = data.drop([\"income\"],axis=1)\n",
    "y_train = data['income'].values\n",
    "X_test = data_test.drop([\"income\"],axis=1)\n",
    "y_test = data_test['income'].values\n",
    "# Classifier\n",
    "classifier = DecisionTreeClassifier(min_samples_leaf=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c3981752b539236e99415ab6e2cbea1f",
     "grade": false,
     "grade_id": "cell-9b18d6c4e381a9f5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**3.1** Draw a learning curve for the classifer for the train and test set loaded above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cebb0d89b3a2b7b278e2494c37ac7c0f",
     "grade": true,
     "grade_id": "cell-905e7dceeb4172c3",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# BEGIN CODE HERE\n",
    "def learning_curve(X,y,classifier):\n",
    "    pass\n",
    "\n",
    "#END CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "361d4753f3c8491a34ff55b6fa3a49b5",
     "grade": false,
     "grade_id": "cell-1f23f3e27600f019",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**3.2** Do you notice any problems with the classifier? If so, what can you do to change this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "baff993106fd2b655fd47d05c75ea4ce",
     "grade": true,
     "grade_id": "cell-d60d7e6175d184e9",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "747645b33cb4f5c14796504fac6bf3ce",
     "grade": false,
     "grade_id": "cell-89715acd6c51b332",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**3.3** Implement your solution using the cells below. Report your results and the process you followed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "53187b3e939fffed99cbba46e3639281",
     "grade": true,
     "grade_id": "cell-f44811f1e99ee41e",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# BEGIN CODE HERE\n",
    "final_score = \"\"\n",
    "\n",
    "#END CODE HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
