{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About iPython Notebooks ##\n",
    "\n",
    "iPython Notebooks are interactive coding environments embedded in a webpage. You will be using iPython notebooks in this class. Make sure you fill in any place that says `# BEGIN CODE HERE #END CODE HERE`. After writing your code, you can run the cell by either pressing \"SHIFT\"+\"ENTER\" or by clicking on \"Run\" (denoted by a play symbol). Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All). \n",
    "\n",
    " **What you need to remember:**\n",
    "\n",
    "- Run your cells using SHIFT+ENTER (or \"Run cell\")\n",
    "- Write code in the designated areas using Python 3 only\n",
    "- Do not modify the code outside of the designated areas\n",
    "- In some cases you will also need to explain the results. There will also be designated areas for that. \n",
    "\n",
    "Fill in your **NAME** and **AEM** below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"Sotiris Ftiakas\"\n",
    "AEM = \"3076\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ce63642cafb413e7903d83d2f2cd3637",
     "grade": false,
     "grade_id": "cell-f62db6dce1ed3f2e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Assignment 2 - Decision Trees #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "29d61ce286fdb8fd61c7f8e89a9e1339",
     "grade": false,
     "grade_id": "cell-dce2e73cee9a5017",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Welcome to your second assignment. This exercise gives you an introduction to [scikit-learn](https://scikit-learn.org/stable/). A simple but efficient machine learning library in Python. It also gives you a wide understanding on how decision trees work. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "50a108d2f1e1a1ee2fde80743c0543fe",
     "grade": false,
     "grade_id": "cell-83ca2b0456fb85db",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "After this assignment you will:\n",
    "- Be able to use the scikit-learn library and train your own model from scratch.\n",
    "- Be able to train and understand decision trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "396c39a0797964c378ebb90cf18a29de",
     "grade": false,
     "grade_id": "cell-2cef6d48eea484d8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Always run this cell\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "import unittest\n",
    "\n",
    "# USE THIS RANDOM VARIABLE TO PRODUCE THE SAME RESULTS\n",
    "RANDOM_VARIABLE = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Scikit-Learn and Decision Trees ##\n",
    "\n",
    "You are going to use the scikit-learn library to train a model for detecting breast cancer using the [Breast cancer wisconsin (diagnostic) dataset](https://scikit-learn.org/stable/datasets/index.html#breast-cancer-wisconsin-diagnostic-dataset) by training a model using [decision trees](https://scikit-learn.org/stable/modules/tree.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.1** Load the breast cancer dataset using the scikit learn library and split the dataset into train and test set using the appropriate function. Use 30% of the dataset as the test set. Define as X the attributes and as y the target values. Do not forget to set the random_state parameter as the *RANDOM_VARIABLE* defined above. Use this variable for all the random_state parameters in this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4b873328ea05f6ef9c08827168c7b835",
     "grade": false,
     "grade_id": "cell-1f0c2f3918333cf6",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# BEGIN CODE HERE\n",
    "\n",
    "X,y = load_breast_cancer(return_X_y = True)\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=RANDOM_VARIABLE)\n",
    "\n",
    "#END CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3603b2ba8916ffdad9e9c53f31546b4c",
     "grade": true,
     "grade_id": "cell-3f43c895ceaf57a9",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train set:398\n",
      "Size of test set:171\n",
      "Unique classes:2\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of train set:{}\".format(len(y_train)))\n",
    "print(\"Size of test set:{}\".format(len(y_test)))\n",
    "print(\"Unique classes:{}\".format(len(set(y_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "62285a7bd3ab59718b89f7e09de0fea4",
     "grade": false,
     "grade_id": "cell-1ce621a108e76a15",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Expected output**:  \n",
    "Size of train set:398  \n",
    "Size of test set:171  \n",
    "Unique classes:2  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.2** Train two DecisionTree classifiers and report the F1 score. Use the information gain for the one classifier and the Gini impurity for the other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "17197b62614427a979fcbab7ed2734dd",
     "grade": false,
     "grade_id": "cell-a7fa1d29509eb2a1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# BEGIN CODE HERE\n",
    "classifier_gini = DecisionTreeClassifier(criterion=\"gini\",random_state=RANDOM_VARIABLE).fit(X_train,y_train)\n",
    "classifier_igain = DecisionTreeClassifier(criterion=\"entropy\",random_state=RANDOM_VARIABLE).fit(X_train,y_train)\n",
    "\n",
    "prediction_gini = classifier_gini.predict(X_test)\n",
    "prediction_igain = classifier_igain.predict(X_test)\n",
    "\n",
    "f_measure_gini = f1_score(y_test,prediction_gini)\n",
    "f_measure_igain = f1_score(y_test,prediction_igain)\n",
    "\n",
    "#END CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6d9aab4355c27c346f7e6548f233e758",
     "grade": true,
     "grade_id": "cell-09657a82bf4028c4",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-Measure Gini:0.9528301886792453\n",
      "F-Measure Information Gain:0.9724770642201834\n"
     ]
    }
   ],
   "source": [
    "print(\"F-Measure Gini:{}\".format(f_measure_gini))\n",
    "print(\"F-Measure Information Gain:{}\".format(f_measure_igain))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f3facbbef0dd8f25ad12bfec7c174818",
     "grade": false,
     "grade_id": "cell-b0d8630f3b764cf3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Expected output**:  \n",
    "F-Measure Gini:0.9528301886792453  \n",
    "F-Measure Information Gain:0.9724770642201834  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f2532168d16e8c9bffba3d7d8e1efce7",
     "grade": false,
     "grade_id": "cell-591ba122016b6db5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**1.3** Find the maximum depth reached by the tree that used the Gini impurity. Train multiple classifier by modifying the max_depth within the range from 1 to maximum depth and save the f1 scores to lists.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "54cf257e90a3cb5877db81297bedd45c",
     "grade": false,
     "grade_id": "cell-31c58b6161a3907d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# BEGIN CODE HERE\n",
    "depth = classifier_gini.tree_.max_depth\n",
    "fscores_train = []\n",
    "fscores_test = []\n",
    "\n",
    "for i in range (1,depth+1):\n",
    "    gini = DecisionTreeClassifier(criterion=\"gini\",random_state=RANDOM_VARIABLE,max_depth=i).fit(X_train,y_train)\n",
    "    pred_gini = gini.predict(X_train)\n",
    "    f_gini = f1_score(y_train,pred_gini)\n",
    "    \n",
    "    fscores_train.append(f_gini)\n",
    "    \n",
    "    gini = DecisionTreeClassifier(criterion=\"gini\",random_state=RANDOM_VARIABLE,max_depth=i).fit(X_train,y_train)\n",
    "    pred_gini = gini.predict(X_test)\n",
    "    f_gini = f1_score(y_test,pred_gini)\n",
    "    \n",
    "    fscores_test.append(f_gini)\n",
    "    \n",
    "\n",
    "\n",
    "#END CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "70a249937f2f690c6ce855debaed204c",
     "grade": true,
     "grade_id": "cell-0c300109423f53b9",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fscores Train:[0.9392712550607287, 0.9533468559837729, 0.9761904761904762, 0.996, 0.996, 0.9979959919839679, 1.0]\n",
      "Fscores Test:[0.9150943396226415, 0.9444444444444444, 0.9724770642201834, 0.9629629629629629, 0.9629629629629629, 0.9674418604651163, 0.9528301886792453]\n"
     ]
    }
   ],
   "source": [
    "print(\"Fscores Train:{}\".format(fscores_train))\n",
    "print(\"Fscores Test:{}\".format(fscores_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3db472d2b9db7a42cc012cd96fdeb499",
     "grade": false,
     "grade_id": "cell-75789627f20d2c94",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Expected output**:  \n",
    "Fscores Train:[0.9392712550607287, 0.9533468559837729, 0.9761904761904762, 0.996, 0.996, 0.9979959919839679, 1.0]  \n",
    "Fscores Test:[0.9150943396226415, 0.9444444444444444, 0.9724770642201834, 0.9629629629629629, 0.9629629629629629, 0.9674418604651163, 0.9528301886792453]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bca7d4c160c767d27a09b4620d27d56e",
     "grade": false,
     "grade_id": "cell-5906e6d5efa70282",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**1.4** Compare the results from the train set with the results from the test set. What do you notice? Explain your findings. How are you going to choose the max_depth of your model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "424ac10e4e22ca9e32207deee3bf0f57",
     "grade": true,
     "grade_id": "cell-c9c6ea0e40d98b83",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "There are **two(2)** things we can notice on the results.\n",
    "\n",
    "**1)** On the **train-f1_scores** list, as we keep on incrementing the max allowed tree depth, at one point we can see that the f1_score is approaching and finally achieving 100% accuracy, meaning that we have completely overfitted our model to the training dataset.\n",
    "\n",
    "**2)** On the **test-f1_scores** list, as we keep on incrementing the max allowed tree depth, at one point we can see that the f1_score starts to fall, meaning that our model is losing accuracy. This means as well, that we have an overfitting problem after a specific tree depth.\n",
    "\n",
    "To choose the max_depth of a model, a good pre-prunning technique is to **use a condition** which will require a node to have a **minimum amount of points before splitting.** \n",
    "Other than that, there is always the option of **trial and error**, where we can try different depths for our model and see which one gives us the best possible accuracy, while avoiding overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #THATS A TESTING CELL\n",
    "\n",
    "# # BEGIN CODE HERE\n",
    "# income = pd.read_csv(\"income.csv\")\n",
    "# income_test = pd.read_csv(\"income_test.csv\")\n",
    "\n",
    "# #print(\"Keys of income_dataset: \\n\\n{}\\n\\n\".format(income.keys()))\n",
    "\n",
    "# cleandata=income.copy()\n",
    "# cleandata_test=income_test.copy()\n",
    "\n",
    "# #The reason I merge the two datasets is because later, due to one hot encoding, the two datasets have different amount\n",
    "# #of columns\n",
    "\n",
    "# cleandata['train']=1\n",
    "# cleandata_test['train']=0\n",
    "# combined=pd.concat([cleandata,cleandata_test])\n",
    "\n",
    "# #Fill missing values, replacing them with each columns' most frequent value.\n",
    "# combined = combined.apply(lambda x:x.fillna(x.value_counts().index[0])) \n",
    "\n",
    "# #Replacing categorical values with One Hot Encoding method (AKA the dummy method).\n",
    "# combined_encoded = pd.get_dummies(combined, columns=['workclass','education','marital-status','occupation','relationship','race','sex','income'])\n",
    "# combined=pd.concat([combined,combined_encoded],axis=1)\n",
    "\n",
    "# #Split the two datasets now\n",
    "\n",
    "# cleandata = combined[combined['train'] == 1]\n",
    "# cleandata_test = combined[combined['train'] == 0]\n",
    "# cleandata.drop(['train'], axis=1, inplace=True)\n",
    "# cleandata_test.drop(['train'], axis=1, inplace=True)\n",
    "\n",
    "# #print(cleandata.describe(include='all'))\n",
    "# print(\"Keys of income_dataset: \\n\\n{}\\n\\n\".format(cleandata.keys()))\n",
    "# print(\"Keys of income_dataset: \\n\\n{}\\n\\n\".format(cleandata_test.keys()))\n",
    "\n",
    "# X_train = cleandata.iloc[:, :-2].values\n",
    "# y_train = cleandata.iloc[:, -2:].values\n",
    "# X_test = cleandata_test.iloc[:, :-2].values\n",
    "# y_test = cleandata_test.iloc[:, -2:].values\n",
    "\n",
    "# classifier = DecisionTreeClassifier(random_state=RANDOM_VARIABLE).fit(X_train,y_train)\n",
    "\n",
    "# #y_pred=classifier.predict(X_test)\n",
    "\n",
    "# #fScore = f1_score(y_test,y_pred)\n",
    "# accScore = \"\"\n",
    "\n",
    "# #END CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "217666fcc2e383d6f2c1904c9d6a71be",
     "grade": false,
     "grade_id": "cell-9ef42e6c90ea2ffe",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 2.0 Pipelines ##\n",
    "\n",
    "**2.1** In this part of the exercise you are going to build a pipeline from scratch for a classification problem. Load the **income.csv** file and train a DecisionTree model that will predict the *income* variable. This dataset is a modification of the original Adult Income dataset found [here](http://archive.ics.uci.edu/ml/datasets/Adult). Report the f1-score and accuracy score of the test set found in **income_test.csv**. Your pipeline should be able to handle missing values and categorical features (scikit-learn's decision trees do not handle categorical values). You can preprocess the dataset as you like in order to achieve higher scores.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "152ab2dd6861b198b879a78ebadc4ee4",
     "grade": true,
     "grade_id": "cell-dd950ab2eb40d8a4",
     "locked": false,
     "points": 45,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score on test set: 0.66905\n",
      "Accuracy on test set: 0.85504\n"
     ]
    }
   ],
   "source": [
    "# BEGIN CODE HERE\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "income = pd.read_csv(\"income.csv\")\n",
    "income_test = pd.read_csv(\"income_test.csv\")\n",
    "\n",
    "#print(\"Keys of income_dataset: \\n\\n{}\\n\\n\".format(income.keys()))\n",
    "\n",
    "cleandata=income.copy()\n",
    "cleandata_test=income_test.copy()\n",
    "\n",
    "#Fill missing values, replacing them with each columns' most frequent value.\n",
    "cleandata = cleandata.apply(lambda x:x.fillna(x.value_counts().index[0])) \n",
    "\n",
    "#Replacing categorical values with One Hot Encoding method (AKA the dummy method).\n",
    "cleandata = pd.get_dummies(cleandata, columns=['workclass','education','marital-status','occupation','relationship','race','sex'])\n",
    "cleandata['income'] = LabelEncoder().fit_transform(cleandata.income.values)\n",
    "\n",
    "cleandata_test = pd.get_dummies(cleandata_test, columns=['workclass','education','marital-status','occupation','relationship','race','sex'])\n",
    "cleandata_test['income'] = LabelEncoder().fit_transform(cleandata_test.income.values)\n",
    "\n",
    "cleandata, cleandata_test = cleandata.align(cleandata_test, join='inner', axis=1)  #Inner join to prevent uneven number of columns\n",
    "\n",
    "#print(cleandata.describe(include='all'))\n",
    "#print(\"Keys of income_dataset: \\n\\n{}\\n\\n\".format(cleandata.keys()))\n",
    "#print(\"Keys of income_dataset: \\n\\n{}\\n\\n\".format(cleandata_test.keys()))\n",
    "\n",
    "X_train = cleandata.drop(['income'],axis=1)\n",
    "y_train = cleandata['income'].values\n",
    "X_test = cleandata_test.drop(['income'],axis=1)\n",
    "y_test = cleandata_test['income'].values\n",
    "\n",
    "# print(X_train)\n",
    "# print(y_train)\n",
    "# print(X_test)\n",
    "# print(y_test)\n",
    "\n",
    "classifier = DecisionTreeClassifier(max_depth=10, random_state=RANDOM_VARIABLE).fit(X_train,y_train)\n",
    "\n",
    "y_pred=classifier.predict(X_test)\n",
    "\n",
    "fScore = f1_score(y_test,y_pred)\n",
    "print(\"F1-score on test set: {:.5f}\".format(fScore))\n",
    "accScore = classifier.score(X_test, y_test)\n",
    "print(\"Accuracy on test set: {:.5f}\".format(accScore))\n",
    "\n",
    "\n",
    "#END CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ee9d4c2635307395bdef2efb941106ae",
     "grade": false,
     "grade_id": "cell-2c3327274958bbad",
     "locked": true,
     "points": 20,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "**2.2** Describe the process you followed to achieve the results above. Your description should include, but is not limited to the following \n",
    "- How do you handle missing values and why\n",
    "- How do you handle categorical variables and why\n",
    "- Any further preprocessing steps\n",
    "- How do you evaluate your model and how did you choose its parameters \n",
    "- Report any additional results and comments on your approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8cef3f333ab449ed91b81ea96695e712",
     "grade": false,
     "grade_id": "cell-555d20216f9bbec2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 3.0 Common Issues ## "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.0** Run the following code to define a DecisionTreeModel and load the **income** dataset only with the numerical variables. Then, answer the following questions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ae0f57b86252cc38b02cac3d05e08bbf",
     "grade": false,
     "grade_id": "cell-d7f58621bad12aad",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Load Data\n",
    "columns = ['age','fnlwgt','education_num','hours-per-week',\"capital-loss\",\"capital-gain\",\"income\"]\n",
    "data = pd.read_csv('income.csv',usecols=columns)\n",
    "data_test = pd.read_csv('income_test.csv',usecols=columns)\n",
    "# Convert target variable to 0 and 1\n",
    "data[\"income\"] = data[\"income\"].map({ \"<=50K\": 0, \">50K\": 1 })\n",
    "data_test[\"income\"] = data_test[\"income\"].map({ \"<=50K\": 0, \">50K\": 1 })\n",
    "# Create X and y\n",
    "X_train = data.drop([\"income\"],axis=1)\n",
    "y_train = data['income'].values\n",
    "X_test = data_test.drop([\"income\"],axis=1)\n",
    "y_test = data_test['income'].values\n",
    "# Classifier\n",
    "classifier = DecisionTreeClassifier(min_samples_leaf=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c3981752b539236e99415ab6e2cbea1f",
     "grade": false,
     "grade_id": "cell-9b18d6c4e381a9f5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**3.1** Draw a learning curve for the classifer for the train and test set loaded above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cebb0d89b3a2b7b278e2494c37ac7c0f",
     "grade": true,
     "grade_id": "cell-905e7dceeb4172c3",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score on test set: 0.48067\n",
      "F1-score on train set: 0.70588\n",
      "F1-score on test set: 0.50581\n",
      "F1-score on train set: 0.82759\n",
      "F1-score on test set: 0.47746\n",
      "F1-score on train set: 0.77692\n",
      "F1-score on test set: 0.52820\n",
      "F1-score on train set: 0.77967\n",
      "F1-score on test set: 0.54300\n",
      "F1-score on train set: 0.77317\n",
      "F1-score on test set: 0.53357\n",
      "F1-score on train set: 0.77395\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# BEGIN CODE HERE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def learning_curve(X_train, X_test, y_train, y_test, classifier):\n",
    "    train_scores=[]\n",
    "    test_scores=[]\n",
    "    num_of_data=[y_train.size//1000, y_train.size//500, y_train.size//50, y_train.size//5, y_train.size//2, y_train.size]\n",
    "    for i in range (0,6):\n",
    "        X_train_less_data = X_train.iloc[0:num_of_data[i]-1]\n",
    "        y_train_less_data = y_train[0:num_of_data[i]-1]\n",
    "        \n",
    "        classifier.fit(X_train_less_data,y_train_less_data)\n",
    "        y_test_pred=classifier.predict(X_test)\n",
    "        y_train_pred=classifier.predict(X_train_less_data)\n",
    "        test_fScore = f1_score(y_test,y_test_pred)\n",
    "        train_fScore = f1_score(y_train_less_data,y_train_pred)\n",
    "        print(\"F1-score on test set: {:.5f}\".format(test_fScore))\n",
    "        print(\"F1-score on train set: {:.5f}\".format(train_fScore))\n",
    "        train_scores.append(train_fScore)\n",
    "        test_scores.append(test_fScore)\n",
    "    plt.plot(num_of_data,train_scores)\n",
    "    plt.show()\n",
    "\n",
    "learning_curve(X_train,X_test,y_train,y_test,classifier)\n",
    "    \n",
    "\n",
    "#I should probalbly make a graph , shown the accuracy in every iteration of the classifier\n",
    "\n",
    "#END CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "361d4753f3c8491a34ff55b6fa3a49b5",
     "grade": false,
     "grade_id": "cell-1f23f3e27600f019",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**3.2** Do you notice any problems with the classifier? If so, what can you do to change this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "baff993106fd2b655fd47d05c75ea4ce",
     "grade": true,
     "grade_id": "cell-d60d7e6175d184e9",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "747645b33cb4f5c14796504fac6bf3ce",
     "grade": false,
     "grade_id": "cell-89715acd6c51b332",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**3.3** Implement your solution using the cells below. Report your results and the process you followed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "53187b3e939fffed99cbba46e3639281",
     "grade": true,
     "grade_id": "cell-f44811f1e99ee41e",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# BEGIN CODE HERE\n",
    "final_score = \"\"\n",
    "\n",
    "#END CODE HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
